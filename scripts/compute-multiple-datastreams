#!/bin/sh
#
# This script takes the raw output of parse-datastreams, say data.csv,
# and then produces a two-column CSV file that lists the number of
# objects that have historical datastreams. This script would be run
# as so:
#
# ./this-script < data.csv > plot.csv
#
# Then you can use some graphing package to display it - I use numbers
# on the mac.
#
# Details: consider a fragment of our data as produced by parse-datastreams:
#
# fau:36200,MODS,MODS.0,2243,2017-08-07T18:46:50.852Z,true
# fau:36200,MODS,MODS.1,2454,2017-08-11T12:19:33.833Z,false
# fau:36200,POLICY,POLICY.0,3532,2017-08-07T18:46:50.852Z,true
# fau:36200,POLICY,POLICY.1,725,2017-08-07T19:16:17.386Z,false
# fsu:8420,MODS,MODS.0,2281,2013-10-22T17:22:40.997Z,true
# fsu:8420,MODS,MODS.1,2281,2016-11-14T21:13:51.196Z,true
# fsu:8420,MODS,MODS.2,2734,2017-07-11T17:05:12.336Z,false
# unf:18318,HOCR,HOCR.0,1,2015-04-24T16:12:13.028Z,true
# unf:18318,HOCR,HOCR.1,21524,2015-04-24T16:12:13.189Z,true
# unf:18318,HOCR,HOCR.2,21524,2015-04-24T16:12:13.414Z,true
# unf:18318,HOCR,HOCR.3,21524,2015-04-24T16:12:13.562Z,false
# unf:18318,OCR,OCR.0,1,2015-04-24T16:12:12.339Z,true
# unf:18318,OCR,OCR.1,1127,2015-04-24T16:12:12.605Z,true
# unf:18318,OCR,OCR.2,1127,2015-04-24T16:12:12.752Z,true
# unf:18318,OCR,OCR.3,1127,2015-04-24T16:12:12.907Z,false
#
# I'm taking us through the processing pipeline, which is:
#
# 1                     2               3      4             5         6         7                  8         9
# grep -v 'false$' $1 | cut -d, -f1,2 | sort | cut -d, -f1 | uniq -c | sort -n | awk '{print $1}' | uniq -c | awk '{print $2 "," $1}'
#
# 1: look at our collected data as in the above and find the extra
# datastreams - false means it's not deletable, it's the one we need
# preserve, so we remove that from our processing
#
# 2 and 3: grab the pid/datastream-id pairs and then sort (sort is
# probably not necessary)
#
# 4: grab just the pid's - so for the above data we'd have:
#
#    fau:36200
#    fau:36200
#    fsu:8420
#    fsu:8420
#    unf:18318
#    unf:18318
#    unf:18318
#    unf:18318
#    unf:18318
#    unf:18318
#
# 5: count them - we have the total number of redundant per islandora digital object
#
# 6: sort by the counts (so '2' would mean there were that many extra
# datastreams for a single object) - for instance,
#
#      2 fau:36200
#      2 fsu:8420
#      6 unf:18318
#
# 7: we need the distributions of the counts so select the first numbers
#
# 8: and count them:
#
#      2 2
#      1 6
#
# the above is understood to mean there are two objects (fau:36200 and fsu:8420) with 2 extra datastreams each, and 1 (unf:18138) with 6.
#
# 9: swap the columns, add a comma: these will be the pairs (extra-datastreams, count), strictly increasing in the number of extra-datastreams:
#
#      2,2
#      6,1
#
# for our example data above: there are 2 objects with 2 extra datastreams, and one with six extra datastreams.
#
# Now when we plot it all of our data, we'll need to do log-linear plot.
#
#
# 1                   2               3      4             5         6         7                  8         9
grep -v 'false$' $1 | cut -d, -f1,2 | sort | cut -d, -f1 | uniq -c | sort -n | awk '{print $1}' | uniq -c | awk '{print $2 "," $1}'
